import streamlit as st
import os
import time
from dotenv import load_dotenv

# Táº£i cÃ¡c biáº¿n mÃ´i trÆ°á»ng (dÃ¹ khÃ´ng dÃ¹ng API á»Ÿ bÆ°á»›c nÃ y, giá»¯ láº¡i lÃ  thÃ³i quen tá»‘t)
load_dotenv()

# --- Cáº¥u hÃ¬nh trang ---
st.set_page_config(
    page_title="Gemini Chat App",
    page_icon="ğŸ¤–",
    layout="centered"
)

# --- Model AI Giáº£ láº­p (Mock AI Model) ---
def get_mock_ai_response(user_message):
    """
    HÃ m nÃ y giáº£ láº­p viá»‡c gá»i Ä‘áº¿n má»™t model AI.
    NÃ³ sáº½ tráº£ vá» má»™t cÃ¢u tráº£ lá»i Ä‘Æ°á»£c láº­p trÃ¬nh sáºµn dá»±a trÃªn tin nháº¯n ngÆ°á»i dÃ¹ng.
    """
    # Chuyá»ƒn tin nháº¯n vá» chá»¯ thÆ°á»ng Ä‘á»ƒ dá»… so sÃ¡nh
    user_message = user_message.lower()
    
    if "xin chÃ o" in user_message:
        return "Xin chÃ o! TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n hÃ´m nay?"
    elif "báº¡n tÃªn lÃ  gÃ¬" in user_message:
        return "TÃ´i lÃ  má»™t trá»£ lÃ½ AI Ä‘Æ°á»£c táº¡o ra Ä‘á»ƒ demo."
    elif "khá»e khÃ´ng" in user_message:
        return "TÃ´i khá»e, cáº£m Æ¡n báº¡n Ä‘Ã£ há»i! CÃ²n báº¡n thÃ¬ sao?"
    else:
        return f"TÃ´i Ä‘Ã£ nháº­n Ä‘Æ°á»£c tin nháº¯n cá»§a báº¡n: '{user_message}'. ÄÃ¢y lÃ  má»™t cÃ¢u tráº£ lá»i máº«u."

# --- Quáº£n lÃ½ Tráº¡ng thÃ¡i PhiÃªn (Session State) ---
# Khá»Ÿi táº¡o lá»‹ch sá»­ chat náº¿u nÃ³ chÆ°a tá»“n táº¡i
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- Giao diá»‡n ngÆ°á»i dÃ¹ng (UI) ---
st.title("ğŸ¤– Chat App Äa NÄƒng")
st.write("TrÃ² chuyá»‡n, phÃ¢n tÃ­ch áº£nh vÃ  dá»¯ liá»‡u CSV.")
st.markdown("---")

# Hiá»ƒn thá»‹ cÃ¡c tin nháº¯n Ä‘Ã£ cÃ³ trong lá»‹ch sá»­
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Ã” nháº­p liá»‡u vÃ  nÃºt gá»­i
if prompt := st.chat_input("Nháº­p cÃ¢u há»i cá»§a báº¡n..."):
    # 1. ThÃªm tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­ vÃ  hiá»ƒn thá»‹
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. Táº¡o pháº£n há»“i tá»« AI vÃ  hiá»ƒn thá»‹
    with st.chat_message("assistant"):
        # Hiá»ƒn thá»‹ chá»‰ bÃ¡o Ä‘ang táº£i (loading spinner)
        with st.spinner("AI Ä‘ang suy nghÄ©... ğŸ¤”"):
            # Gá»i model AI giáº£ láº­p
            response = get_mock_ai_response(prompt)
            # Giáº£ láº­p thá»i gian xá»­ lÃ½
            time.sleep(1) 
            st.markdown(response)
    
    # 3. ThÃªm pháº£n há»“i cá»§a AI vÃ o lá»‹ch sá»­
    st.session_state.messages.append({"role": "assistant", "content": response})